{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method A - Try Classification Decision Tree with no max depth\n",
    "#1 Load in Kaggle training data\n",
    "#2 Train/Test Split\n",
    "#3 Vectorize\n",
    "#4 Instantiate \n",
    "\n",
    "#1 - Load in Kaggle training dataset\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import dummy\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "with open('/Users/alirossi/Desktop/recipe-ingredients-dataset/train.json') as f:\n",
    "    dict_train = json.load(f)\n",
    "\n",
    "recipe = pd.DataFrame(dict_train)\n",
    "recipe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X (which contains dummy variables for each ingredient) and y\n",
    "\n",
    "X = pd.get_dummies(recipe['ingredients'].apply(pd.Series).stack()).sum(level=0)\n",
    "y = recipe['cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Train/Test Split - split into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate null accuracy - use Dummy Classifier, predict all recipes are Italian \n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=31)\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Classification Decision Tree with no max depth\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "treeclf = DecisionTreeClassifier(random_state=31)\n",
    "treeclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature':X_train.columns, 'importance':treeclf.feature_importances_})\\\n",
    "    .sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source(tree.export_graphviz(treeclf, out_file='tree_recipe.png', feature_names=X_train.columns))\n",
    "#export_graphviz(treeclf, out_file='tree_recipe.svg', feature_names=X_train.columns, max_depth=2)\n",
    "graph = Source(tree.export_graphviz(treeclf, out_file=None, feature_names=X_train.columns, max_depth=5))\n",
    "SVG(graph.pipe(format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to test w test set\n",
    "y_pred = treeclf.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix   \n",
    "print(classification_report(y_test, y_pred))\n",
    "#precision = % true positive out of all predicted positives - 55% of Brazilian predictions were true\n",
    "#recall = % true positive out of all actual positives - 43% of Brazilian recipes were predicted to be Brazilian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred, labels=['brazilian','british','cajun_creole','chinese','filipino','french'\\\n",
    "                                              ,'greek','indian','irish','italian','jamaican','japanese','korean',\\\n",
    "                                              'mexican','moroccan','russian','southern_us','spanish','thai',\\\n",
    "                                              'vietnamese'])) \n",
    "#header row = class predicted by model\n",
    "#first column = actual classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B - Classification Decision Tree with optimized max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeclf = DecisionTreeClassifier(random_state=31, max_depth=20)\n",
    "treeclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'feature':X_train.columns, 'importance':treeclf.feature_importances_})\\\n",
    "    .sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to test w test set\n",
    "y_pred = treeclf.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix   \n",
    "print(classification_report(y_test, y_pred))\n",
    "#precision = % true positive out of all predicted positives \n",
    "#recall = % true positive out of all actual positives\n",
    "#Not much better playing with max depth - now the less-represented recipes are not being predicted at all since their\n",
    "#ingredients are not being used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features=5 is best and n_estimators=150 is sufficiently large.\n",
    "rfclf = RandomForestClassifier(n_estimators=150, max_features=None, oob_score=True, random_state=31)\n",
    "rfclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature importances.\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':rfreg.feature_importances_}).sort_values(by='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Things we can try:\n",
    "# - Classification Decision Tree x\n",
    "# - Random Forest\n",
    "# - As opposed to looking at discrete ingredients, just look at words/n-grams in ingredient list\n",
    "# - Remove spaces to make ingredients all one word\n",
    "# - Predict with % probabilities\n",
    "# - Josh M. suggestion - use TFIDF (or LDA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
